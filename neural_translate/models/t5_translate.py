# -*- coding: utf-8 -*-
"""t5_translate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qEwkcSOVdnpC_4clfK7AEt_rl5gScf9i
"""

import torch
from datasets import load_dataset, Dataset
from evaluate import evaluator
from torch.optim import AdamW
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm
from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments
from transformers import T5TokenizerFast, T5ForConditionalGeneration
from transformers import get_constant_schedule_with_warmup

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


def load_opus_dataset(src, tgt, tokenizer):
    dataset = load_dataset("opus_euconst", f"{src}-{tgt}")

    dataset = dataset.shuffle(seed=42)

    dataset["validation"] = Dataset.from_dict(dataset["train"][:int(len(dataset["train"]) / 10)],
                                              features=dataset["train"].features)

    dataset["train"] = Dataset.from_dict(dataset["train"][int(len(dataset["train"]) / 10):],
                                         features=dataset["train"].features)

    def tokenization(sample):
        model_inputs = tokenizer(sample["translation"]["en"], padding=True, truncation=True)

        labels = tokenizer(text_target=sample["translation"]["it"], padding=True, truncation=True)

        model_inputs["labels"] = labels["input_ids"]
        return model_inputs

    dataset = dataset.map(tokenization, batched=False, batch_size=None, remove_columns=["translation"])

    return dataset


def predict(model, tokenizer, sentence):
    temp = tokenizer.encode(sentence, return_tensors="pt").to(DEVICE)

    model.eval()
    with torch.no_grad():
        out = model.generate(temp)

    return tokenizer.decode(out[0], skip_special_tokens=True)


def evaluate(model, tokenizer):
    with open("../data/dataset/newssyscomb2009.en", "r") as file:
        data_en = file.read()

    with open("../data/dataset/newssyscomb2009.it", "r") as file:
        data_it = file.read()

    test_dataset = Dataset.from_dict({"text": data_en.split("\n"), "label": data_it.split("\n")})

    task_evaluator = evaluator("translation")

    results = task_evaluator.compute(
        model_or_pipeline=model,
        data=test_dataset,
        tokenizer=tokenizer,
        metric="bleu")
    return results


tokenizer = T5TokenizerFast.from_pretrained("t5-base")

model = T5ForConditionalGeneration.from_pretrained("t5-base").to(DEVICE)

dataset = load_opus_dataset("en", "it", tokenizer)

config = {
    "lr": 5e-05,
    "epochs": 25,
    "batch_size": 4
}

data_collator = DataCollatorForSeq2Seq(
    tokenizer,
    model=model,
    label_pad_token_id=tokenizer.pad_token_id
)

train_loader = DataLoader(
    dataset["train"],
    batch_size=config["batch_size"],
    collate_fn=data_collator
)

optimizer = AdamW(model.parameters(), lr=config["lr"], betas=(0.9, 0.999), eps=1e-08)
lr_scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=2000)

trainer = Seq2SeqTrainer(
    model=model,
    args=Seq2SeqTrainingArguments(output_dir="dummy_dir"),
    eval_dataset=dataset["validation"],
    data_collator=data_collator,
)


def train_epoch(model, optimizer, lr_scheduler, train_loader):
    train_loss_epoch = torch.tensor(0.0).to(DEVICE)
    epoch_samples = 0
    for step, inputs in tqdm(enumerate(train_loader), total=len(train_loader)):
        model.train()
        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}
        outputs = model(**inputs)
        outputs["loss"].backward()
        train_loss_epoch += outputs["loss"].detach() * len(inputs)
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)

        optimizer.step()

        lr_scheduler.step()

        model.zero_grad()
        epoch_samples += len(inputs)
    return train_loss_epoch.cpu().item() / epoch_samples


model.zero_grad()
for epoch in range(config["epochs"]):
    train_loss = train_epoch(model, optimizer, lr_scheduler, train_loader)
    eval_results = trainer.evaluate()
    print(f"TRAIN LOSS: {train_loss}, EVAL LOSS: {eval_results['eval_loss']}")
